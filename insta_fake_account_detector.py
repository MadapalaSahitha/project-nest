# -*- coding: utf-8 -*-
"""insta fake account detector

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-tGtQ4Hqj2t-maO4zsp5baAsz9rsI2um
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Dense, Activation, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.metrics import Accuracy

from sklearn import metrics
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report,accuracy_score,roc_curve,confusion_matrix

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import warnings

warnings.filterwarnings("ignore")


def fxn():
    warnings.warn("deprecated", DeprecationWarning)

with warnings.catch_warnings():
    warnings.filterwarnings("ignore", category=DeprecationWarning)
    fxn()

instagram_df_train=pd.read_csv('train.csv')
instagram_df_train

instagram_df_test=pd.read_csv('test (2).csv')
instagram_df_test

instagram_df_train.head()

instagram_df_train.tail()

# Getting dataframe info
instagram_df_train.info()

instagram_df_train.describe()

instagram_df_train.isnull().sum()

instagram_df_train['profile pic'].value_counts()

instagram_df_train['fake'].value_counts()

sns.countplot(instagram_df_train['fake'])
plt.show()

sns.countplot(instagram_df_train['private'])
plt.show()

sns.countplot(instagram_df_train['profile pic'])
plt.show()

plt.figure(figsize = (20, 10))
sns.distplot(instagram_df_train['nums/length username'])
plt.show()

# Correlation plot
plt.figure(figsize=(20, 20))
cm = instagram_df_train.corr()
ax = plt.subplot()
sns.heatmap(cm, annot = True, ax = ax)
plt.show()

X_train = instagram_df_train.drop(columns = ['fake'])
X_test = instagram_df_test.drop(columns = ['fake'])
X_train

# Training and testing dataset (Outputs)
y_train = instagram_df_train['fake']
y_test = instagram_df_test['fake']
y_train

from sklearn.preprocessing import StandardScaler, MinMaxScaler

scaler_x = StandardScaler()
X_train = scaler_x.fit_transform(X_train)
X_test = scaler_x.transform(X_test)

y_train = tf.keras.utils.to_categorical(y_train, num_classes = 2)
y_test = tf.keras.utils.to_categorical(y_test, num_classes = 2)

y_train

import tensorflow.keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential()
model.add(Dense(50, input_dim=11, activation='relu'))
model.add(Dense(150, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(150, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(25, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(2,activation='softmax'))

model.summary()

model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

epochs_hist = model.fit(X_train, y_train, epochs = 50,  verbose = 1, validation_split = 0.1)

print(epochs_hist.history.keys())

print(epochs_hist.history.keys())

predicted = model.predict(X_test)

predicted_value = []
test = []
for i in predicted:
    predicted_value.append(np.argmax(i))

for i in y_test:
    test.append(np.argmax(i))

print(classification_report(test, predicted_value))

plt.figure(figsize=(10, 10))
cm=confusion_matrix(test, predicted_value)
sns.heatmap(cm, annot=True)
plt.show()

loss, accuracy = model.evaluate(X_test, y_test)
print("Test Loss:", loss)
print("Test Accuracy:", accuracy)

# Assuming model.predict(X_test) returns probabilities for each class
y_pred_prob = model.predict(X_test)
# Convert probabilities to class labels based on threshold (e.g., 0.5)
y_pred = (y_pred_prob > 0.5).astype(int)

# Now, y_pred contains the predicted class labels
print(classification_report(y_test, y_pred))

import numpy as np

# Define the preprocess_data function
def preprocess_data(profile_pic, nums_length_username, fullname_words, nums_length_fullname, name_username, description_length, external_URL, private, num_posts, num_followers, num_follows):
    data = [profile_pic, nums_length_username, fullname_words, nums_length_fullname, name_username, description_length, external_URL, private, num_posts, num_followers, num_follows]
    return np.array([data])

# Assuming you have loaded your trained model and test data
# model = load_model('path_to_your_model.h5')
# X_test, y_test = load_test_data('path_to_your_test_data.npy')

# Preprocess input data
profile_pic = 1
nums_length_username = 10
fullname_words = 2
nums_length_fullname = 20
name_username = 1
description_length = 30
external_URL = 0
private = 1
num_posts = 100
num_followers = 500
num_follows = 200

processed_data = preprocess_data(profile_pic, nums_length_username, fullname_words, nums_length_fullname, name_username, description_length, external_URL, private, num_posts, num_followers, num_follows)

# Make prediction
prediction = model.predict(processed_data)

print("Processed Data:", processed_data)
print("Prediction Probabilities:", prediction)

model.save("insta_fake_account_detector_model.h5")